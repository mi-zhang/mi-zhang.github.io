<!DOCTYPE html>
<html lang="en">
<head>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Mi Zhang</title>
    <meta name="keywords" content="Mi, Zhang, Mi Zhang, mizhang, USC, University of Southern California,
        OSU, The Ohio State University,
        AIoT, Edge AI, Machine Learning Systems, Mobile Computing, Mobile Health" />
    <meta name="description" content="" />

    <link type="image/x-icon" href="https://www.osu.edu/assets/web/favicon/favicon.ico" rel="shortcut icon">

    <link rel="stylesheet" href="../styles/main.css">
</head>

<body>
    <div class="container">
        <header class="header">
            <div class="header-content">
                <a href="../index.html">
                    <div class="header-left">
                        Mi Zhang
                    </div>
                </a>
                <div class="header-right">
                    <a href="https://www.osu.edu/">
                        <img src="./imgs/headerOSULogo.svg" alt="" class="headerOSULogo">
                    </a>
                </div>
            </div>
        </header>

        <nav class="navbar">
          <ul>
            <li><a href="../index.html">Home</a></li>
            <li><a href="./news.html">News</a></li>
            <li><a href="./publications.html">Publications</a></li>
            <li><a href="./service.html">Service</a></li>
            <li><a href="./group.html">Group</a></li>
            <li><a href="./teaching.html">Teaching</a></li>
            <li><a href="./talks.html">Talks</a></li>
            <li><a href="./media.html">Media</a></li>
            <li><a href="https://sites.google.com/view/osu-aiot-seminar">OSU AIoT Seminar</a></li>
          </ul>
        </nav>

        <div class="body_container">
            <section id="news" class="section">
                <div class="section_title">News</div>
                <br>
                <ul>
                    <li>
                        <div class="highlight1">08/2025:</div> Our <a href="https://arxiv.org/abs/2401.01923">vision paper</a> won the 2024 <font color="#de1111"><b>Best Paper Award</b></font> of IEEE Internet Computing Magazine.
                    </li>
                    <li>
                        <div class="highlight1">05/2025:</div> MEIT, our work on multimodal LLM-based ECG report generation is accepted to ACL.
                    </li>
                    <li>
                        <div class="highlight1">04/2025:</div> Our survey on efficient diffusion models is accepted to Transactions on Machine Learning Research (TMLR).
                    </li>
                    <li>
                        <div class="highlight1">02/2025:</div> D2O and MEDA, our series work on Large Language Model and Multimodal Large Language Model KV cache compression for efficient long-context inference are accepted to ICLR'25 and NAACL'25.
                    </li>
                    <li>
                        <div class="highlight1">02/2025:</div> SVD-LLM and SVD-LLM V2, our series work on post-training Large Language Model compression are accepted to ICLR'25 and NAACL'25.
                    </li>
                    <li>
                        <div class="highlight1">01/2025:</div> Thanks Meta Reality Labs for the generous faculty award for supporting our research.
                    </li>
                    <li>
                        <div class="highlight1">12/2024:</div> Thanks NVIDIA for the generous NVIDIA academic grant for supporting our research.
                    </li>
                    <li>
                        <div class="highlight1">09/2024:</div> Very honored to receive the 2024 University of Chicago Outstanding Educator Award.
                    </li>
                    <li>
                            <div class="highlight1">09/2024:</div> <a href="papers/2024_ECCVW_Famba-V.pdf">Famba-V</a>, our work on efficient Vision Mamba won the <font color="#de1111"><b>Best Paper Award</b></font> of ECCV'24 Workshop on Computational Aspects of Deep Learning sponsored by NVIDIA.
                    </li>
                    <li>
                            <div class="highlight1">08/2024:</div> In collaboration with MSU, USC, and UCLA, our <a href="papers/2024_ACMTOSN_AIoTSurvey.pdf">survey</a> on Artificial Intelligence of Things (AIoT) is accepted to ACM Transactions on Sensor Networks. We also create a <a href="https://github.com/AIoT-MLSys-Lab/AIoT-Survey">GitHub repository</a> where we organize the papers featured in this survey. We hope this survey along with the GitHub repository could serve as valuable resources to help researchers and practitioners gain a comprehensive understanding of AIoT research and inspire them to contribute to this important and exciting field.
                    </li>
                    <li>
                            <div class="highlight1">08/2024:</div> Recent advancements in Generative AI have enabled a new wave of AI revolution. The implications of such advancements for Internet of Things (IoT) are profound. In our <a href="https://arxiv.org/abs/2401.01923">vision paper</a> accepted to IEEE Internet Computing Magazine, we share our views on the applications, challenges, and opportunities of IoT in the era of Generative AI.
                    </li>
                    <li>
                            <div class="highlight1">08/2024:</div> <a href="papers/2024_DMLR_FedAIoT.pdf">FedAIoT</a>, our work on developing a dedicated federated learning framework and benchmark for IoT devices is accepted to Journal of Data-centric Machine Learning Research (DMLR).
                    </li>
                    <li>
                            <div class="highlight1">06/2024:</div> Co-chairing the <a href="https://www.sigmobile.org/mobisys/2024/iot.html">IoT Day</a> at this year's ACM MobiSys with Chenren Xu from Peking University. We have an amazing program with five stellar keynotes and an exciting and timely panel on IoT in the era of Generative AI.
                    </li>
                    <li>
                            <div class="highlight1">05/2024:</div> In collaboration with Imperial College London, MSU, University of Michigan, Amazon, Google Research, Microsoft Research, and Boson AI, our <a href="papers/2024_TMLR_EfficientLLMSurvey.pdf">survey</a> on efficient large language models is accepted to Transactions on Machine Learning Research (TMLR). We have also created a <a href="https://github.com/AIoT-MLSys-Lab/Efficient-LLMs-Survey">GitHub repository</a> where we organize the papers featured in this survey.
                    </li>
                    <li>
                            <div class="highlight1">03/2024:</div> Invited to attend the research summit for egocentric perception hosted by Meta Reality Lab. The future of AR glasses is bright!
                    </li>
                    <li>
                            <div class="highlight1">03/2024:</div> Congratulations Zhongwei, Xin and Hyunho for landing internship at Tencent AI Lab, Microsoft Research and AMD!
                    </li>
                    <li>
                            <div class="highlight1">03/2024:</div> Congratulations Zhongwei for being invited to give a <a href="https://www.youtube.com/watch?v=WHhdrwCnyrk&t=4s&ab_channel=StanfordMedAI">talk</a> at Stanford MedAI Seminar Series!
                    </li>
                    <li>
                            <div class="highlight1">02/2024:</div> Congratulations Xin for being awarded the highly competitive OSU College Allocated Fellowship!
                    </li>
                    <li>
                            <div class="highlight1">09/2023:</div> Thanks NSF for the NeTS Medium grant to support our project on high-performing LoRa with Edge AI.
                    </li>
                    <li>
                        <div class="highlight1">02/2023:</div> Extremely honored to receive the inaugural <a href="https://minghsiehece.usc.edu/groups-and-institutes-sipi-sipi-50th-anniversary-awardees/">USC ECE SIPI Distinguished Alumni Award</a> in the Junior/Academia category for my contributions to mobile/edge computing in my early career.
                    </li>
                    <li>
                        <div class="highlight1">01/2023:</div> Congratulations Samiul for being awarded the highly competitive OSU College Allocated Fellowship!
                    </li>
                    <li>
                        <div class="highlight1">12/2022:</div> Thanks Meta Reality Labs for the generous faculty award for supporting our research!
                    </li>
                    <li>
                        <div class="highlight1">09/2022:</div> <a href="https://arxiv.org/abs/2212.01548">FedRolex</a>, our work on model-heterogeneous federated learning is accepted to NeurIPS'22.
                    </li>
                    <li>
                        <div class="highlight1">08/2022:</div> After eight amazing years at MSU, our group has joined Department of Computer Science and Engineering at OSU.
                    </li>
                    <li>
                        <div class="highlight1">08/2022:</div> Congratulations Shen for denfending his PhD thesis! Wish you all the best at Google Research!
                    </li>
                    <li>
                        <div class="highlight1">07/2022:</div> Invited to give a talk at Meta (Facebook) to talk about how we build efficient, scalable, and inclusive federated learning systems.
                    </li>
                    <li>
                        <div class="highlight1">03/2022:</div> Our <a href="https://arxiv.org/abs/2111.07494">vision paper</a> on enabling federated learning on potentially billions of IoT devices is published at IEEE Internet of Things Magazine (IEEE IoTM).
                    </li>
                    <li>
                        <div class="highlight1">01/2022:</div> Congratulations Shen for landing his summer internship at Google Brain!
                    </li>
                    <li>
                        <div class="highlight1">01/2022:</div> <a href="papers/2022_ICLR_DeepAA.pdf">Deep AutoAugment</a>, our AutoML work on deep data augmentation policy search is accepted to ICLR'22.
                    </li>
                    <li>
                        <div class="highlight1">01/2022:</div> <a href="papers/2022_MobiCom_PyramidFL.pdf">PyramidFL</a> (Client Selection for Federated Learning) is accepted to ACM MobiCom'22.
                    </li>
                    <li>
                        <div class="highlight1">12/2021:</div> Invited to give a talk at the <a href="https://viterbi.usc.edu/calendar/?event=69936#user_options">USC Center for Cyber-Physical Systems and Internet of Things Seminar</a>.
                    </li>
                    <li>
                        <div class="highlight1">11/2021:</div> <a href="papers/2021_SenSys_NELoRa.pdf">NELoRa</a> won the <font color="#de1111"><b>Best Paper Award</b></font> at ACM SenSys'21, and is selected as ACM SIGMOBILE Research Highlight.
                    </li>
                    <li>
                        <div class="highlight1">11/2021:</div> Invited to attend this year's Google Workshop on Federated Learning and Analytics.
                    </li>
                    <li>
                        <div class="highlight1">10/2021:</div> Invited to give a talk at the <a href="https://mlsys.stanford.edu/">Stanford Machine Learning Systems (MLSys) Seminar</a>.
                    </li>
                    <li>
                        <div class="highlight1">09/2021:</div> <a href="papers/2021_SenSys_Mercury.pdf">Mercury</a> (On-Device Distributed DNN Training), <a href="papers/2021_SenSys_FedMask.pdf">FedMask</a> (Federated Learning), and <a href="papers/2021_SenSys_NELoRa.pdf">NELoRa</a> (AI-enhanced LoRa) are accepted to ACM SenSys'21.
                    </li>
                    <li>
                        <div class="highlight1">07/2021:</div> In collaboration with many colleagues, we are very excited to publish <a href="https://arxiv.org/abs/2107.06917">A Field Guide to Federated Optimization</a>, a paper that serves as a guide on federated learning research.
                    </li>
                    <li>
                        <div class="highlight1">05/2021:</div> Congratulations Xiao for denfending his PhD thesis! Wish you all the best at Amazon!
                    </li>
                    <li>
                        <div class="highlight1">05/2021:</div> <a href="https://arxiv.org/abs/2102.07108">CATE</a>, our AutoML work on neural architecture search based on computation-aware neural architecture encoding is accepted as long talk (top 3%) at ICML'21.
                    </li>
                    <li>
                        <div class="highlight1">05/2021:</div> Congratulations Shen and Yu for landing their internships at Google Research and Amazon!
                    </li>
                    <li>
                        <div class="highlight1">04/2021:</div> Invited to give a Keynote at <a href="https://sites.google.com/view/automl2021">ICML'21 AutoML Workshop</a>.
                    </li>
                    <li>
                        <div class="highlight1">04/2021:</div> Our book <a href="https://item.jd.com/12830375.html">创新工场讲AI课：从知识到实践 (Chinese)</a> is published.
                    </li>
                    <li>
                        <div class="highlight1">12/2020:</div> <a href="https://arxiv.org/abs/2007.13518">FedML</a> won the <font color="#de1111"><b>Best Paper Award</b></font> at NeurIPS'20 Federated Learning Workshop.
                    </li>
                    <li>
                        <div class="highlight1">10/2020:</div> Invited to attend and give a talk at the Facebook AI Systems Faculty Summit.
                    </li>
                    <li>
                        <div class="highlight1">09/2020:</div> <a href="papers/2020_NeurIPS_arch2vec.pdf">arch2vec</a>, our AutoML work on neural architecture search based on unsupervised architecture representation learning is accepted to NeurIPS'20.
                    </li>
                    <li>
                        <div class="highlight1">09/2020:</div> <a href="papers/2020_SenSys_Distream.pdf">Distream</a>, our distributed deep learning framework for large-scale video analytics is accepted to ACM SenSys'20.
                    </li>
                    <li>
                        <div class="highlight1">09/2020:</div> <a href="papers/2020_SenSys_WiSIA.pdf">WiSIA (Wi-Fi See It All)</a> is accepted to ACM SenSys'20.
                    </li>
                    <li>
                        <div class="highlight1">08/2020:</div> Invited to give a tutorial on AutoML at <a href="https://hangzhang.org/ECCV2020/">ECCV'20 Tutorial session: From HPO to NAS: Automated Deep Learning</a>.
                    </li>
                    <li>
                        <div class="highlight1">08/2020:</div> <a href="papers/2020_SEC_FlexDNN.pdf">FlexDNN</a>, our on-device deep learning framework for efficient mobile vision is accepted to ACM/IEEE SEC'20 and is the <font color="#de1111"><b>Best Paper Award Nominee</b></font>.
                    </li>
                    <li>
                        <div class="highlight1">07/2020:</div> In collaboration with many colleagues, we are very excited to introduce <a href="https://arxiv.org/abs/2007.13518">FedML</a>, a research library and benchmark for federated learning.
                    </li>
                    <li>
                        <div class="highlight1">07/2020:</div> Invited to attend the Workshop on Federated Learning and Analytics hosted by Google.
                    </li>
                    <li>
                        <div class="highlight1">07/2020:</div> <a href="papers/2020_ECCV_MutualNet.pdf">MutualNet</a> is accepted as oral (top 2%) at ECCV'20. MutualNet is an adaptive ConvNet that is able to achieve adaptive accuracy-efficiency trade-offs at runtime for on-device AI.
                    </li>
                    <li>
                        <div class="highlight1">05/2020:</div> Congratulations Xiao, Yu, and Shen for landing their internships at Amazon and ByteDance!
                    </li>
                    <li>
                        <div class="highlight1">04/2020:</div> Thanks Amazon AWS AI for the <a href="https://www.amazon.science/research-awards/program-updates/2019-q4-aws-machine-learning-research-awards-recipients-announced">AWS Machine Learning Research Award</a>!
                    </li>
                    <li>
                        <div class="highlight1">03/2020:</div> <a href="papers/2020_MobiSys_SecWIR.pdf">SecWIR</a> is accepted to ACM MobiSys'20.
                    </li>
                    <li>
                        <div class="highlight1">02/2020:</div> Thanks Facebook Research for the <a href="https://research.fb.com/blog/2020/02/announcing-the-winners-of-the-systems-for-machine-learning-rfp/">Facebook Faculty Research Award on Systems for Machine Learning</a>!
                    </li>
                    <li>
                        <div class="highlight1">02/2020:</div> Our AI-enabled smart hearing aid receives the <a href="https://innovationcenter.msu.edu/events/2020-innovation-celebration/mi-zhang-innovation-of-the-year/">2020 MSU Innovation of the Year Award</a>!
                    </li>
                    <li>
                        <div class="highlight1">12/2019:</div> Congratulations Biyi for denfending his PhD thesis! Wish you all the best at Microsoft!
                    </li>
                    <li>
                        <div class="highlight1">12/2019:</div> We are the <font color="#de1111"><b>4th Place Winner (1st Place in U.S. and Canada)</b></font> of the Google MicroNet Challenge CIFAR-100 Track hosted at NeurIPS'19! <a href="https://micronet-challenge.github.io/leaderboard.html">Official Announcement</a>. This is our third global competition win over the past 4 years. We have made our algorithm <a href="https://github.com/MSU-MLSys-Lab/MSUNet">open source</a>, and hope it can push the research area of on-device/edge AI forward.
                    </li>
                    <li>
                        <div class="highlight1">08/2019:</div> <a href="papers/2019_ICCVW_HM-NAS.pdf">HM-NAS</a>, our AutoML work on weight-sharing based neural architecture search is the <font color="#de1111"><b>Best Paper Award Candidate</b></font> at ICCV'19 Neural Architects Workshop.
                    </li>
                    <li>
                        <div class="highlight1">05/2019:</div> Congratulations Shen for landing his internship at Bosch Research!
                    </li>
                    <li>
                        <div class="highlight1">08/2018:</div> Thanks NSF for the NeTS Small grant (Co-PI) to fund our Mobile Internet of Things (Mobile IoT) project!
                    </li>
                    <li>
                        <div class="highlight1">07/2018:</div> <a href="papers/2018_MobiCom_NestDNN.pdf">NestDNN</a>, our on-device deep learning framework that enables resource-aware multi-tenant on-device AI is accepted to ACM MobiCom'18.
                    </li>
                    <li>
                        <div class="highlight1">05/2018:</div> <a href="papers/2018_CNS_WiFiCalling.pdf">The Dark Side of Operational Wi-Fi Calling Services</a> won the <font color="#de1111"><b>Best Paper Award</b></font> at IEEE CNS'18. The work reported in this paper also won the Google Security Reward.
                    </li>
                    <li>
                        <div class="highlight1">05/2018:</div> Congratulations Biyi for landing his internship at Microsoft!
                    </li>
                    <li>
                        <div class="highlight1">04/2018:</div> Our <a href="papers/2018_GetMobile_UbiquitousMR.pdf">vision paper</a> on realizing ubiquitous mixed reality by combining Internet of Things (IoT) and mixed reality (MR) is published at ACM SIGMOBILE GetMobile. Our <a href="papers/2018_UbiComp_JARVIS.pdf">ACM UbiComp'18 paper</a> is one concrete realization of this vision.
                    </li>
                    <li>
                        <div class="highlight1">12/2017:</div> Invited to serve on the Technical Advisory Board of the <a href="https://grandchallenges.ucla.edu/depression/">UCLA Depression Grand Challenge</a>.
                    </li>
                    <li>
                        <div class="highlight1">09/2017:</div> Interviewed by <a href="https://www.wired.com/story/to-compete-with-new-rivals-chipmaker-nvidia-shares-its-secrets/?ncid=so-twi-nl-22946">WIRED</a> to share my view on NVIDIA's Deep Learning Accelerator and on accelerating deep learning on mobile and embedded devices.
                    </li>
                    <li>
                        <div class="highlight1">08/2017:</div> We are the <font color="#de1111"><b>Third Place Winner</b></font> of the NSF Hearables Challenge!
                        <a href="https://ninesights.ninesigma.com/web/hearables/innovationcontest">Official NSF Announcement</a>. We are <a href="http://ubicomp.org/ubicomp2017/program/nsfhearableschallenge.html">invited by NSF</a> to present our work at ACM UbiComp'17.
                        Media coverage:
                        <a href="https://cacm.acm.org/news/222774-tune-out-background-noise-with-msus-new-technology/fulltext">ACM TechNews</a>,
                        <a href="https://www.tun.com/blog/msu-technology-hearing-aid-noise/">TUN</a>,
                        <a href="https://www.rdmag.com/news/2017/11/hearing-aid-technology-eliminate-background-noise">R&amp;D Magazine</a>,
                        <a href="https://www.aau.edu/research-scholarship/featured-research-topics/msu-hearing-aid-technology-eliminate-background-noise">AAU</a>,
                        <a href="http://msutoday.msu.edu/news/2017/msu-hearing-aid-technology-to-eliminate-background-noise/">MSU Today</a>.
                    </li>
                    <li>
                        <div class="highlight1">07/2017:</div> <a href="papers/2017_SenSys_DeepASL.pdf">DeepASL</a>, our deep learning based American sign language (ASL) translation system that enables ubiquitous and non-intrusive ASL translation at both word and sentence levels is accepted to ACM SenSys'17.
                        Media coverage:
                        <a href="https://www.youtube.com/watch?v=TwI1aeWz9Dc">NSF (video)</a>,
                        <a href="https://www.youtube.com/watch?v=7HzUr9let48">MSU (video)</a>,
                        <a href="https://news.developer.nvidia.com/ai-can-interpret-and-translate-american-sign-language-sentences/">NVIDIA</a>,
                        <a href="https://www.michiganradio.org/post/stateside-asl-translation-technology-ingham-countys-first-public-defender-sen-peters-pfas">NPR (radio interview)</a>,
                        <a href="https://www.smithsonianmag.com/innovation/sign-language-translators-are-cool-but-are-they-useful-180971535/">Smithsonian</a>,
                        <a href="https://www.aau.edu/research-scholarship/featured-research-topics/new-technology-breaks-through-sign-language-barriers">AAU</a>,
                        <a href="https://www.futurity.org/sign-language-translator-1984022/">Futurity</a>,
                        <a href="https://msutoday.msu.edu/news/2019/new-technology-breaks-through-sign-language-barriers/">MSU Today</a>.
                    </li>
                    <li>
                        <div class="highlight1">05/2017:</div> Our <a href="http://www.annualreviews.org/doi/abs/10.1146/annurev-clinpsy-032816-044949">review paper</a> on personal sensing and machine learning for digital mental health is published at the Annual Review of Clinical Psychology (Impact Factor: 12.214).
                    </li>
                    <li>
                        <div class="highlight1">04/2017:</div> Honored to be selected as the 2017 NIH Mobile Health (mHealth) Scholar!
                    </li>
                    <li>
                        <div class="highlight1">02/2017:</div> <a href="papers/2017_MobiSys_MobileDeepPill.pdf">MobileDeepPill</a>, our <a href="https://www.nlm.nih.gov/news/pillimagerecognitionchallenge.html">award-winning</a> on-device deep learning based mobile pill recognition system is accepted to ACM MobiSys'17.
                    </li>
                    <li>
                        <div class="highlight1">09/2016:</div> Thanks NSF for the PFI:BIC grant (PI)! We are very grateful for receiving this grant to develop personal sensing technologies and mobile sensor data analytics techniques to combat depression on university campuses.
                        Media coverage:
                        <a href="https://www.youtube.com/watch?v=1dtQAvhaIuk">NSF (video)</a>,
                        <a href="http://www.smithsonianmag.com/innovation/how-mobile-technology-can-help-universities-combat-depression-180961795/">Smithsonian Magazine</a>,
                        <a href="http://msutoday.msu.edu/news/2016/1-million-nsf-grant-to-enhance-college-counseling-services/">MSU Today</a>,
                        <a href="http://www.edtechmagazine.com/higher/article/2016/11/michigan-state-university-app-helps-college-students-depression">EdTech</a>,
                        <a href="http://www.itechpost.com/articles/30025/20160915/depression-and-anxiety-treated-through-smartphone-counseling-on-msu-campus.htm">iTechPost</a>, etc.
                    </li>
                    <li>
                        <div class="highlight1">08/2016:</div> We are the <font color="#de1111"><b>First Place Winner</b></font> of the NIH Pill Image Recognition Challenge!
                        <a href="https://www.nlm.nih.gov/news/pillimagerecognitionchallenge.html">Official NIH Announcement</a> |
                        Media coverage:
                        <a href="http://msutoday.msu.edu/news/2016/nih-challenge-winner-helping-solve-pill-recognition-problem/">MSU Today</a>,
                        <a href="http://www.wxyz.com/news/msu-professor-working-on-mobile-solution-to-identify-pills">ABC News (TV)</a>, etc.
                    </li>
                    <li>
                        <div class="highlight1">08/2016:</div> Thanks NSF for the CSR Small grant (PI)!
                    </li>
                    <li>
                        <div class="highlight1">08/2016:</div> Honored to receive the NSF CRII Award!
                        Media coverage:
                        <a href="http://msutoday.msu.edu/news/2016/msu-technology-could-help-keep-elderly-safe-in-their-homes/">MSU Today</a>,
                        <a href="http://cacm.acm.org/news/206887-msu-technology-could-help-keep-elderly-safe-in-their-homes/fulltext">ACM TechNews</a>,
                        <a href="http://michiganradio.org/post/msu-researcher-studying-new-way-monitor-risk-senior-citizens">NPR</a>,
                        <a href="http://www.wxyz.com/news/wi-fi-signals-could-keep-tabs-on-health-of-aging-family-members-msu-exploring-possibilities">ABC News (TV)</a>, etc.
                    </li>
                    <li>
                        <div class="highlight1">05/2016:</div> Congratulations Biyi for landing his internship at Intel Labs!
                    </li>
                    <li>
                        <div class="highlight1">05/2016:</div> <a href="papers/2016_UbiComp_AirSense.pdf">AirSense</a>, our AIoT system for indoor air quality sensing and analytics is accepted to ACM UbiComp'16.
                        Media coverage:
                        <a href="https://www.theatlantic.com/sponsored/dyson/are-you-polluting-your-own-home/1838/">The Atlantic</a>,
                        <a href="http://msutoday.msu.edu/news/2016/new-technology-monitors-indoor-air-quality/">MSU Today</a>,
                        <a href="http://www.futurity.org/airsense-indoor-pollution-1295542-2/">Futurity</a>, etc.
                    </li>
                    <li>
                        <div class="highlight1">02/2016:</div> <a href="papers/2016_MobiSys_BodyScan.pdf">BodyScan</a>, our wireless sensing system for contactless activity and vital sign monitoring is accepted to ACM MobiSys'16.
                    </li>
                    <li>
                        <div class="highlight1">01/2016:</div> <a href="papers/2016_IPSN_HeadScan.pdf">HeadScan</a>, our wireless sensing system for contactless activity monitoring is accepted to ACM/IEEE IPSN'16. Media coverage:
                        <a href="http://scopeblog.stanford.edu/2016/05/25/engineers-develop-new-type-of-wearable-device/">Stanford Medicine</a>,
                        <a href="http://www.fox2detroit.com/good-day/194845994-story">Fox News (TV interview)</a>,
                        <a href="http://readwrite.com/2016/05/23/health-wearable-monitors-patients-depression-ht4/">ReadWrite</a>,
                        <a href="http://www.futurity.org/headscan-wearables-1165962-2/?utm_source=Futurity+Today&utm_campaign=4b768f71bd-May_19_20165_19_2016&utm_medium=email&utm_term=0_e34e8ee443-4b768f71bd-206324325">Futurity</a>,
                        <a href="http://msutoday.msu.edu/news/2016/wearable-technology-could-help-detect-health-risks-depression/">MSU Today</a>,
                        <a href="http://www.medgadget.com/2016/05/headscan-keeps-jaw-radar-view.html">Medgadget</a>.
                    </li>
                    <li>
                        <div class="highlight1">09/2015:</div> Congratulations Biyi for landing his internship at Bell Labs!
                    </li>
                    <li>
                        <div class="highlight1">07/2015:</div> <a href="papers/2015_UbiComp_DoppleSleep.pdf">DoppleSleep</a>, our device-free wireless sensing system for contactless sleep monitoring won the <font color="#de1111"><b>Best Paper Honorable Mention Award</b></font> at ACM UbiComp'15. Media coverage:
                        <a href="http://www.technologyreview.com/news/539961/got-sleep-problems-try-tracking-your-rest-with-radar/">MIT Technology Review</a>, etc.
                    </li>
                    <li>
                        <div class="highlight1">07/2015:</div> <a href="papers/2015_UbiComp_MyBehavior.pdf">MyBehavior</a>, our reinforcement learning-based mobile recommendation system is accepted to ACM UbiComp'15. Media coverage:
                        <a href="http://www.technologyreview.com/news/539721/a-health-tracking-app-you-might-actually-stick-with/">MIT Technology Review</a>,
                        <a href="http://mashable.com/2015/07/30/health-tracking-app/">Mashable</a>,
                        <a href="https://www.mobihealthnews.com/45795/cornell-researchers-use-personalized-algorithm-in-weight-loss-app/">MobiHealth News</a>, etc.
                    </li>
                    <li>
                        <div class="highlight1">07/2015:</div> Our <a href="http://www.jmir.org/2015/7/e175/">paper</a> on personal sensing for depression detection using mobile phone sensors and machine learning is accepted to JMIR.
                        It is one of the <font color="#de1111"><b>JMIR All-Time Top Article</b></font> now. See the rank <a href="http://www.jmir.org/stats/overview">here</a>.
                        Media coverage:
                        <a href="http://time.com/3958128/smartphone-depression/">TIME</a>,
                        <a href="http://www.cnn.com/2015/07/15/health/smartphone-depression-diagnosis/">CNN</a>,
                        <a href="http://techcrunch.com/2015/07/16/your-phone-can-tell-whether-youre-depressed/">TechCrunch</a>,
                        <a href="http://www.theverge.com/2015/7/15/8970269/smartphone-depression-mental-health-detect">The Verge</a>,
                        <a href="http://www.cbsnews.com/news/phone-habits-depression-mental-health/">CBS News</a>,
                        <a href="http://www.foxnews.com/health/2015/07/15/smartphone-sensors-may-detect-depression-study-says/">Fox News</a>,
                        <a href="http://news.discovery.com/tech/gear-and-gadgets/depressed-your-phone-already-knows-150715.htm">Discovery News</a>,
                        <a href="http://www.dailymail.co.uk/health/article-3162416/How-SMARTPHONE-diagnose-depression-Using-68-minutes-day-sign-mental-illness.html">Daily Mail</a>,
                        <a href="https://www.thetimes.co.uk/article/check-on-your-phone-for-signs-of-depression-vjf2q0jfh6v">The Times</a>,
                        <a href="http://www.newsweek.com/black-box-how-your-phone-can-tell-youre-depressed-354099">Newsweek</a>,
                        <a href="http://www.mirror.co.uk/lifestyle/health/smartphone-behaviour-could-diagnose-depression-6073355">Mirror</a>,
                        <a href="http://www.telegraph.co.uk/news/science/science-news/11741234/Spend-an-hour-on-your-smartphone-daily-You-could-be-depressed.html">The Telegraph</a>,
                        <a href="http://www.washingtonpost.com/news/to-your-health/wp/2015/07/16/how-your-cellphone-knows-if-youre-depressed-it-has-to-do-with-how-you-move-through-time-and-space/">The Washington Post</a>,
                        <a href="http://www.huffingtonpost.com/entry/your-phone-can-tell-if-youre-depressed_55a53e03e4b0b8145f73a97f">The Huffington Post</a>,
                        <a href="http://www.latimes.com/science/sciencenow/la-sci-sn-depressed-cellphone-20150715-story.html">Los Angeles Times</a>,
                        <a href="http://www.chicagotribune.com/bluesky/originals/ct-northwestern-feinberg-study-smartphones-depression-bsi-20150715-story.html">Chicago Tribune</a>,
                        <a href="http://www.futurity.org/depression-iphone-960892/">Futurity</a>,
                        <a href="https://www.webmd.com/depression/news/20150715/daily-smartphone-use-might-offer-clues-to-depression#1">WebMD</a>,
                        <a href="http://www.usnews.com/news/articles/2015/07/15/phones-can-help-detect-if-youre-depressed-study-says">US News</a>, etc.
                    </li>
                    <li>
                        <div class="highlight1">06/2014:</div> <a href="papers/2014_MobiSys_BodyBeat.pdf">BodyBeat</a>, our mobile sensing system that listens to sounds inside human body for continuous health monitoring is accepted to ACM MobiSys'14, and is selected as ACM SIGMOBILE Research Highlight.
                        Media coverage:
                        <a href="http://www.technologyreview.com/news/528386/wearable-self-tracking-tool-listens-for-yawns-coughs-and-munches/">MIT Tech Review</a>,
                        <a href="http://blogs.wsj.com/digits/2014/07/03/chainsaws-gunshots-and-coughs-our-smartphones-are-listening/">Wall Street Journal</a>,
                        <a href="http://www.newscientist.com/article/mg22229734.900-listen-to-sounds-inside#.VAZpWPldV8F">New Scientist</a>.
                    </li>

                </ul>
            </section>

        </div>

        <div class='footerBox'>
            <div class='lineFooter'></div>
            <div class='footerContent'>
              <div class='footerLeft'>
                <div class='footerLogo'>
                  <a href="https://www.osu.edu/">
                    <img src="../imgs/osu-horiz-gray.svg" alt="" />
                  </a>
                </div>
                <div class='footerAddr'>
                  <div class='footerAddrTitle'>© 2025 Mi Zhang</div>
                </div>
              </div>

              <div class='footerMiddle'>
                <div class='footerContactTitle'>
                  Contact
                </div>
                <div class='footerContactContent'>
                    Email: mizhang.1@osu.edu <br>
                    Office: 495 Dreese Labs <br>
                    2015 Neil Ave, Columbus, OH 43210
                  </div>
              </div>

              <div class='footerRight'>
                <div class='footerContactTitle'>
                  Affiliations
                </div>
                <div class='footerContactContent'>
                  <a href="https://cse.osu.edu/">Department of Computer Science and Engineering</a> <br />
                  <a href="https://icdt.osu.edu/">Institute for Cybersecurity and Digital Trust</a> <br />
                  <a href="https://tdai.osu.edu/">Translational Data Analytics Institute</a> <br />
                  <a href="https://5g-oh.osu.edu/">5G and Broadband Connectivity Center</a>
                </div>
              </div>
            </div>
          </div>
    </div>
    <button id="backToTop" class="back-to-top">
        <svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
            <polyline points="18 15 12 9 6 15"></polyline>
        </svg>
    </button>
</body>

<script>
    const backToTopButton = document.getElementById('backToTop');
    window.addEventListener('scroll', () => {
        if (window.scrollY > 300) {
            backToTopButton.classList.add('show');
        } else {
            backToTopButton.classList.remove('show');
        }
    });

    backToTopButton.addEventListener('click', () => {
        window.scrollTo({
            top: 0,
            behavior: 'smooth'
        });
    });
</script>
